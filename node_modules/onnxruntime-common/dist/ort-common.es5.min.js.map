{"version":3,"sources":["webpack://ort/webpack/universalModuleDefinition","webpack://ort/webpack/bootstrap","webpack://ort/webpack/runtime/define property getters","webpack://ort/webpack/runtime/hasOwnProperty shorthand","webpack://ort/webpack/runtime/make namespace object","webpack://ort/./lib/backend-impl.ts","webpack://ort/./lib/env.ts","webpack://ort/./lib/env-impl.ts","webpack://ort/./lib/tensor-impl.ts","webpack://ort/./lib/tensor.ts","webpack://ort/./lib/inference-session.ts","webpack://ort/./lib/inference-session-impl.ts"],"names":["root","factory","exports","module","define","amd","self","__webpack_require__","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","backends","backendsSortedByPriority","registerBackend","name","backend","priority","init","createSessionHandler","TypeError","currentBackend","undefined","Error","i","indexOf","splice","length","push","resolveBackend","backendHints","backendNames","errors","backendName","backendInfo","initialized","aborted","isInitializing","initPromise","err","map","e","join","env","this","wasm","webgl","logLevelInternal","isBigInt64ArrayAvailable","BigInt64Array","from","isBigUint64ArrayAvailable","BigUint64Array","NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP","Map","Float32Array","Uint8Array","Int8Array","Uint16Array","Int16Array","Int32Array","Float64Array","Uint32Array","NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP","set","arg0","arg1","arg2","type","data","dims","Array","isArray","typedArrayConstructor","firstElementType","mappedType","constructor","size","dim","Number","isSafeInteger","RangeError","calculateSize","reshape","Tensor","handler","run","feeds","fetches","options","isFetchesEmpty","outputNames","isFetches","arg1Keys","getOwnPropertyNames","v","inputNames","results","returnValue","create","arg3","filePathOrUint8Array","ArrayBuffer","SharedArrayBuffer","buffer","byteOffset","byteLength","eps","executionProviders","InferenceSession","startProfiling","endProfiling"],"mappings":";;;;;CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,GAAIH,GACe,iBAAZC,QACdA,QAAa,IAAID,IAEjBD,EAAU,IAAIC,GACf,CATD,CASGK,MAAM,WACT,O,wBCTA,IAAIC,EAAsB,CCA1BA,EAAwB,SAASL,EAASM,GACzC,IAAI,IAAIC,KAAOD,EACXD,EAAoBG,EAAEF,EAAYC,KAASF,EAAoBG,EAAER,EAASO,IAC5EE,OAAOC,eAAeV,EAASO,EAAK,CAAEI,YAAY,EAAMC,IAAKN,EAAWC,IAG3E,ECPAF,EAAwB,SAASQ,EAAKC,GAAQ,OAAOL,OAAOM,UAAUC,eAAeC,KAAKJ,EAAKC,EAAO,ECCtGT,EAAwB,SAASL,GACX,oBAAXkB,QAA0BA,OAAOC,aAC1CV,OAAOC,eAAeV,EAASkB,OAAOC,YAAa,CAAEC,MAAO,WAE7DX,OAAOC,eAAeV,EAAS,aAAc,CAAEoB,OAAO,GACvD,G,yJCQMC,EAA0C,CAAC,EAC3CC,EAAqC,GAY9BC,EAAkB,SAACC,EAAcC,EAAkBC,GAC9D,IAAID,GAAmC,mBAAjBA,EAAQE,MAA+D,mBAAjCF,EAAQG,qBA8BpE,MAAM,IAAIC,UAAU,uBA7BlB,IAAMC,EAAiBT,EAASG,GAChC,QAAuBO,IAAnBD,EACFT,EAASG,GAAQ,CAACC,QAAO,EAAEC,SAAQ,OAC9B,IAAII,EAAeJ,SAAWA,EAEnC,OACK,GAAII,EAAeJ,WAAaA,GACjCI,EAAeL,UAAYA,EAC7B,MAAM,IAAIO,MAAM,4BAA4BR,EAAI,oBAAoBE,E,CAIxE,GAAIA,GAAY,EAAG,CACjB,IAAMO,EAAIX,EAAyBY,QAAQV,IAChC,IAAPS,GACFX,EAAyBa,OAAOF,EAAG,GAGrC,IAAK,IAAI,EAAI,EAAG,EAAIX,EAAyBc,OAAQ,IACnD,GAAIf,EAASC,EAAyB,IAAII,UAAYA,EAEpD,YADAJ,EAAyBa,OAAO,EAAG,EAAGX,GAI1CF,EAAyBe,KAAKb,E,CAMpC,EAUac,EAAiB,SAAMC,GAA+B,O,OAAA,E,OAAA,E,EAAA,W,ymCAC3DC,EAAuC,IAAxBD,EAAaH,OAAed,EAA2BiB,EACtEE,EAAS,G,IACW,EAAAD,E,sBAAA,YAAY,Y,GAA3BE,EAAW,OACdC,EAActB,EAASqB,IACzB,YACF,GAAIC,EAAYC,YACd,MAAO,CAAP,EAAOD,EAAYlB,SACd,GAAIkB,EAAYE,QACrB,YAGIC,IAAmBH,EAAYI,Y,iBAKnC,O,uBAHKD,IACHH,EAAYI,YAAcJ,EAAYlB,QAAQE,QAEhD,GAAMgB,EAAYI,a,OAElB,OAFA,SACAJ,EAAYC,aAAc,EACnB,CAAP,EAAOD,EAAYlB,S,yBAEdqB,GACHL,EAAOJ,KAAK,CAACb,KAAMkB,EAAaM,IAAK,IAEvCL,EAAYE,SAAU,E,2BAEfF,EAAYI,Y,kBAvBC,I,aA4B1B,MAAM,IAAIf,MAAM,oCAAoCS,EAAOQ,KAAI,SAAAC,GAAK,UAAIA,EAAE1B,KAAI,KAAK0B,EAAEF,GAAjB,IAAwBG,KAAK,O,iBA/BhC,K,+QCgDtDC,EAAW,IC/GxB,WACE,aACEC,KAAKC,KAAO,CAAC,EACbD,KAAKE,MAAQ,CAAC,EACdF,KAAKG,iBAAmB,SAC1B,CAyBF,OAtBE,sBAAI,uBAAQ,C,IASZ,WACE,OAAOH,KAAKG,gBACd,E,IAXA,SAAapC,GACX,QAAcW,IAAVX,EAAJ,CAGA,GAAqB,iBAAVA,IAA2F,IAArE,CAAC,UAAW,OAAQ,UAAW,QAAS,SAASc,QAAQd,GACxF,MAAM,IAAIY,MAAM,8BAA8BZ,GAEhDiC,KAAKG,iBAAmBpC,C,CAC1B,E,gCAcF,EA9BA,ICOMqC,EAAoD,oBAAlBC,eAA+D,mBAAvBA,cAAcC,KACxFC,EAAsD,oBAAnBC,gBAAiE,mBAAxBA,eAAeF,KAG3FG,EAAwC,IAAIC,IAA6C,CAC7F,CAAC,UAAWC,cACZ,CAAC,QAASC,YACV,CAAC,OAAQC,WACT,CAAC,SAAUC,aACX,CAAC,QAASC,YACV,CAAC,QAASC,YACV,CAAC,OAAQJ,YACT,CAAC,UAAWK,cACZ,CAAC,SAAUC,eAIPC,EAAwC,IAAIT,IAAiD,CACjG,CAACC,aAAc,WACf,CAACC,WAAY,SACb,CAACC,UAAW,QACZ,CAACC,YAAa,UACd,CAACC,WAAY,SACb,CAACC,WAAY,SACb,CAACC,aAAc,WACf,CAACC,YAAa,YAGZd,IACFK,EAAsCW,IAAI,QAASf,eACnDc,EAAsCC,IAAIf,cAAe,UAEvDE,IACFE,EAAsCW,IAAI,SAAUZ,gBACpDW,EAAsCC,IAAIZ,eAAgB,WAQ5D,ICsLa,EDvKb,WAIE,WACIa,EAAoDC,EACpDC,GACF,IAAIC,EACAC,EACAC,EAEJ,GAAoB,iBAATL,EAMT,GAFAG,EAAOH,EACPK,EAAOH,EACM,WAATF,EAAmB,CAErB,IAAKM,MAAMC,QAAQN,GACjB,MAAM,IAAI9C,UAAU,kDAItBiD,EAAOH,C,KACF,CAEL,IAAMO,EAAwBpB,EAAsClD,IAAI8D,GACxE,QAA8B3C,IAA1BmD,EACF,MAAM,IAAIrD,UAAU,4BAA4B6C,EAAI,KAEtD,GAAIM,MAAMC,QAAQN,GAKhBG,EAAQI,EAA8BvB,KAAKgB,OACtC,MAAIA,aAAgBO,GAGzB,MAAM,IAAIrD,UAAU,KAAKgD,EAAI,kCAAkCK,GAF/DJ,EAAOH,C,OAUX,GADAI,EAAOJ,EACHK,MAAMC,QAAQP,GAAO,CAEvB,GAAoB,IAAhBA,EAAKtC,OACP,MAAM,IAAIP,UAAU,uDAEtB,IAAMsD,SAA0BT,EAAK,GACrC,GAAyB,WAArBS,EACFN,EAAO,SACPC,EAAOJ,MACF,IAAyB,YAArBS,EAOT,MAAM,IAAItD,UAAU,uCAAuCsD,EAAgB,KAN3EN,EAAO,OAIPC,EAAOb,WAAWN,KAAKe,E,MAIpB,CAEL,IAAMU,EACFZ,EAAsC5D,IAAI8D,EAAKW,aACnD,QAAmBtD,IAAfqD,EACF,MAAM,IAAIvD,UAAU,qCAAqC6C,EAAKW,YAAW,KAE3ER,EAAOO,EACPN,EAAOJ,C,CAKX,QAAa3C,IAATgD,EAEFA,EAAO,CAACD,EAAK1C,aACR,IAAK4C,MAAMC,QAAQF,GACxB,MAAM,IAAIlD,UAAU,0CAItB,IAAMyD,EAtGY,SAACP,GAErB,IADA,IAAIO,EAAO,EACFrD,EAAI,EAAGA,EAAI8C,EAAK3C,OAAQH,IAAK,CACpC,IAAMsD,EAAMR,EAAK9C,GACjB,GAAmB,iBAARsD,IAAqBC,OAAOC,cAAcF,GACnD,MAAM,IAAI1D,UAAU,QAAQI,EAAC,8BAA8BsD,GAE7D,GAAIA,EAAM,EACR,MAAM,IAAIG,WAAW,QAAQzD,EAAC,0CAA0CsD,GAE1ED,GAAQC,C,CAEV,OAAOD,CACT,CAyFiBK,CAAcZ,GAC3B,GAAIO,IAASR,EAAK1C,OAChB,MAAM,IAAIJ,MAAM,iBAAiBsD,EAAI,gCAAgCR,EAAK1C,OAAM,MAGlFiB,KAAK0B,KAAOA,EACZ1B,KAAKwB,KAAOA,EACZxB,KAAKyB,KAAOA,EACZzB,KAAKiC,KAAOA,CACd,CAeF,OAJE,YAAAM,QAAA,SAAQb,GACN,OAAO,IAAIc,EAAOxC,KAAKwB,KAAMxB,KAAKyB,KAAMC,EAC1C,EAEF,EA/GA,G,60CEqTa,EC5Wb,WACE,WAAoBe,GAClBzC,KAAKyC,QAAUA,CACjB,CA6LF,OA1LQ,YAAAC,IAAN,SAAUC,EAAkBrB,EAA+BC,G,kIAIzD,GAHMqB,EAA4C,CAAC,EAC/CC,EAAsB,CAAC,EAEN,iBAAVF,GAAgC,OAAVA,GAAkBA,aAAiB,GAAUhB,MAAMC,QAAQe,GAC1F,MAAM,IAAInE,UACN,iGAKN,GAFIsE,GAAiB,EAED,iBAATxB,EAAmB,CAC5B,GAAa,OAATA,EACF,MAAM,IAAI9C,UAAU,2CAEtB,GAAI8C,aAAgB,EAClB,MAAM,IAAI9C,UAAU,gCAGtB,GAAImD,MAAMC,QAAQN,GAAO,CACvB,GAAoB,IAAhBA,EAAKvC,OACP,MAAM,IAAIP,UAAU,uCAItB,IAFAsE,GAAiB,EAEZ,EAAL,EAAmB,EAAAxB,EAAA,eAAM,CACvB,GAAoB,iBADXnD,EAAI,MAEX,MAAM,IAAIK,UAAU,kDAEtB,IAAwC,IAApCwB,KAAK+C,YAAYlE,QAAQV,GAC3B,MAAM,IAAIkE,WAAW,2CAA2ClE,EAAI,KAEtEyE,EAAQzE,GAAQ,I,CAGlB,GAAoB,iBAAToD,GAA8B,OAATA,EAC9BsB,EAAUtB,OACL,QAAoB,IAATA,EAChB,MAAM,IAAI/C,UAAU,+B,KAEjB,CAKL,IAFIwE,GAAY,EACVC,EAAW7F,OAAO8F,oBAAoB5B,GACvC,EAAL,EAAmB,EAAAtB,KAAK+C,YAAL,eAAR5E,EAAI,MACmB,IAA5B8E,EAASpE,QAAQV,KAET,QADJgF,EAAK7B,EAA4DnD,KACrDgF,aAAa,KAC7BH,GAAY,EACZF,GAAiB,EACjBF,EAAQzE,GAAQgF,GAKtB,GAAIH,GACF,GAAoB,iBAATzB,GAA8B,OAATA,EAC9BsB,EAAUtB,OACL,QAAoB,IAATA,EAChB,MAAM,IAAI/C,UAAU,qCAGtBqE,EAAUvB,C,OAGT,QAAoB,IAATA,EAChB,MAAM,IAAI9C,UAAU,2DAItB,IAAK,EAAL,EAAmB,EAAAwB,KAAKoD,WAAL,eACjB,GADSjF,EAAI,UACc,IAAhBwE,EAAMxE,GACf,MAAM,IAAIQ,MAAM,UAAUR,EAAI,4BAKlC,GAAI2E,EACF,IAAK,EAAL,EAAmB,EAAA9C,KAAK+C,YAAL,eAAR5E,EAAI,KACbyE,EAAQzE,GAAQ,KAMJ,SAAM6B,KAAKyC,QAAQC,IAAIC,EAAOC,EAASC,I,OAEvD,IAAW3F,KAFLmG,EAAU,SACVC,EAA2C,CAAC,EAChCD,EACZjG,OAAOO,eAAeC,KAAKyF,EAASnG,KACtCoG,EAAYpG,GAAO,IAAI,EAAOmG,EAAQnG,GAAKsE,KAAM6B,EAAQnG,GAAKuE,KAAM4B,EAAQnG,GAAKwE,OAGrF,MAAO,CAAP,EAAO4B,G,QAQI,EAAAC,OAAb,SACIlC,EAAyCC,EAA8BC,EACvEiC,G,4GAKF,GAFIX,EAA0B,CAAC,EAEX,iBAATxB,GAET,GADAoC,EAAuBpC,EACH,iBAATC,GAA8B,OAATA,EAC9BuB,EAAUvB,OACL,QAAoB,IAATA,EAChB,MAAM,IAAI9C,UAAU,qCAEjB,GAAI6C,aAAgBT,YAEzB,GADA6C,EAAuBpC,EACH,iBAATC,GAA8B,OAATA,EAC9BuB,EAAUvB,OACL,QAAoB,IAATA,EAChB,MAAM,IAAI9C,UAAU,oCAEjB,MACH6C,aAAgBqC,aACc,oBAAtBC,mBAAqCtC,aAAgBsC,mBAoC/D,MAAM,IAAInF,UAAU,uDAhCpB,GAHMoF,EAASvC,EACXwC,EAAa,EACbC,EAAazC,EAAKyC,WACF,iBAATxC,GAA8B,OAATA,EAC9BuB,EAAUvB,OACL,GAAoB,iBAATA,EAAmB,CAEnC,GADAuC,EAAavC,GACRa,OAAOC,cAAcyB,GACxB,MAAM,IAAIxB,WAAW,oCAEvB,GAAIwB,EAAa,GAAKA,GAAcD,EAAOE,WACzC,MAAM,IAAIzB,WAAW,oCAAoCuB,EAAOE,WAAU,MAG5E,GADAA,EAAazC,EAAKyC,WAAaD,EACX,iBAATtC,EAAmB,CAE5B,GADAuC,EAAavC,GACRY,OAAOC,cAAc0B,GACxB,MAAM,IAAIzB,WAAW,oCAEvB,GAAIyB,GAAc,GAAKD,EAAaC,EAAaF,EAAOE,WACtD,MAAM,IAAIzB,WAAW,qCAAoCuB,EAAOE,WAAaD,GAAU,MAEzF,GAAoB,iBAATL,GAA8B,OAATA,EAC9BX,EAAUW,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIhF,UAAU,+B,MAEjB,QAAoB,IAAT+C,EAChB,MAAM,IAAI/C,UAAU,iC,MAEjB,QAAoB,IAAT8C,EAChB,MAAM,IAAI9C,UAAU,gCAEtBiF,EAAuB,IAAI7C,WAAWgD,EAAQC,EAAYC,E,CAQ5C,OAFVC,EAAMlB,EAAQmB,oBAAsB,GACpC9E,EAAe6E,EAAInE,KAAI,SAAAhB,GAAK,MAAa,iBAANA,EAAiBA,EAAIA,EAAET,IAA9B,IAClB,GAAMc,EAAeC,I,OACrB,SADA,SACcX,qBAAqBkF,EAAsBZ,I,OACzE,MAAO,CAAP,EAAO,IAAIoB,EADK,W,QAIlB,YAAAC,eAAA,WACElE,KAAKyC,QAAQyB,gBACf,EACA,YAAAC,aAAA,WACEnE,KAAKyC,QAAQ0B,cACf,EAEA,sBAAI,yBAAU,C,IAAd,WACE,OAAOnE,KAAKyC,QAAQW,UACtB,E,gCACA,sBAAI,0BAAW,C,IAAf,WACE,OAAOpD,KAAKyC,QAAQM,WACtB,E,gCAGF,EAhMA,G","file":"ort-common.es5.min.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"ort\"] = factory();\n\telse\n\t\troot[\"ort\"] = factory();\n})(self, function() {\nreturn ","// The require scope\nvar __webpack_require__ = {};\n\n","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: {[name: string]: BackendInfo} = {};\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @internal\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createSessionHandler === 'function') {\n    const currentBackend = backends[name];\n    if (currentBackend === undefined) {\n      backends[name] = {backend, priority};\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends[backendsSortedByPriority[i]].priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @internal\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends[backendName];\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init();\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {EnvImpl} from './env-impl';\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  webgl: Env.WebGLFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = new EnvImpl();\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env';\n\ntype LogLevelType = Env['logLevel'];\nexport class EnvImpl implements Env {\n  constructor() {\n    this.wasm = {};\n    this.webgl = {};\n    this.logLevelInternal = 'warning';\n  }\n\n  // TODO standadize the getter and setter convention in env for other fields.\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    this.logLevelInternal = value;\n  }\n  get logLevel(): LogLevelType {\n    return this.logLevelInternal;\n  }\n\n  debug?: boolean;\n\n  wasm: Env.WebAssemblyFlags;\n\n  webgl: Env.WebGLFlags;\n\n  [name: string]: unknown;\n\n  private logLevelInternal: Required<LogLevelType>;\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor as TensorInterface} from './tensor';\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\n\ntype SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\ntype SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\nconst isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\nconst isBigUint64ArrayAvailable = typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nconst NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nconst NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, TensorType>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\nif (isBigInt64ArrayAvailable) {\n  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n}\nif (isBigUint64ArrayAvailable) {\n  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n}\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nconst calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\nexport class Tensor implements TensorInterface {\n  // #region constructors\n  constructor(type: TensorType, data: TensorDataType|readonly number[]|readonly boolean[], dims?: readonly number[]);\n  constructor(data: TensorDataType|readonly boolean[], dims?: readonly number[]);\n  constructor(\n      arg0: TensorType|TensorDataType|readonly boolean[], arg1?: TensorDataType|readonly number[]|readonly boolean[],\n      arg2?: readonly number[]) {\n    let type: TensorType;\n    let data: TensorDataType;\n    let dims: typeof arg1|typeof arg2;\n    // check whether arg0 is type or data\n    if (typeof arg0 === 'string') {\n      //\n      // Override: constructor(type, data, ...)\n      //\n      type = arg0;\n      dims = arg2;\n      if (arg0 === 'string') {\n        // string tensor\n        if (!Array.isArray(arg1)) {\n          throw new TypeError('A string tensor\\'s data must be a string array.');\n        }\n        // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n        // error will be populated at inference\n        data = arg1;\n      } else {\n        // numeric tensor\n        const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n        if (typedArrayConstructor === undefined) {\n          throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n        }\n        if (Array.isArray(arg1)) {\n          // use 'as any' here because TypeScript's check on type of 'SupportedTypedArrayConstructors.from()' produces\n          // incorrect results.\n          // 'typedArrayConstructor' should be one of the typed array prototype objects.\n          // eslint-disable-next-line @typescript-eslint/no-explicit-any\n          data = (typedArrayConstructor as any).from(arg1);\n        } else if (arg1 instanceof typedArrayConstructor) {\n          data = arg1;\n        } else {\n          throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n        }\n      }\n    } else {\n      //\n      // Override: constructor(data, ...)\n      //\n      dims = arg1;\n      if (Array.isArray(arg0)) {\n        // only boolean[] and string[] is supported\n        if (arg0.length === 0) {\n          throw new TypeError('Tensor type cannot be inferred from an empty array.');\n        }\n        const firstElementType = typeof arg0[0];\n        if (firstElementType === 'string') {\n          type = 'string';\n          data = arg0;\n        } else if (firstElementType === 'boolean') {\n          type = 'bool';\n          // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n          // wrong type. We use 'as any' to make it happy.\n          // eslint-disable-next-line @typescript-eslint/no-explicit-any\n          data = Uint8Array.from(arg0 as any[]);\n        } else {\n          throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n        }\n      } else {\n        // get tensor type from TypedArray\n        const mappedType =\n            NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n        if (mappedType === undefined) {\n          throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n        }\n        type = mappedType;\n        data = arg0 as SupportedTypedArray;\n      }\n    }\n\n    // type and data is processed, now processing dims\n    if (dims === undefined) {\n      // assume 1-D tensor if dims omitted\n      dims = [data.length];\n    } else if (!Array.isArray(dims)) {\n      throw new TypeError('A tensor\\'s dims must be a number array');\n    }\n\n    // perform check\n    const size = calculateSize(dims);\n    if (size !== data.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${data.length}).`);\n    }\n\n    this.dims = dims as readonly number[];\n    this.type = type;\n    this.data = data;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly data: TensorDataType;\n  readonly size: number;\n  // #endregion\n\n  // #region tensor utilities\n  reshape(dims: readonly number[]): Tensor {\n    return new Tensor(this.type, this.data, dims);\n  }\n  // #endregion\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor as TensorImpl} from './tensor-impl';\nimport {TypedTensorUtils} from './tensor-utils';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: never;  // hold on using Uint16Array before we have a concrete solution for float 16\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: never;  // hold on before we have a concret solution for float 16\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\nexport interface TensorConstructor {\n  // #region specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly boolean[], dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the tensor data\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as TensorConstructor;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl';\nimport {OnnxValue} from './onnx-value';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm' and 'xnnpack'.\n  // Backend ONNX.js: supports 'webgl'.\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {SessionHandler} from './backend';\nimport {resolveBackend} from './backend-impl';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session';\nimport {OnnxValue} from './onnx-value';\nimport {Tensor} from './tensor';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: SessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        returnValue[key] = new Tensor(results[key].type, results[key].data, results[key].dims);\n      }\n    }\n    return returnValue;\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createSessionHandler(filePathOrUint8Array, options);\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: SessionHandler;\n}\n"],"sourceRoot":""}